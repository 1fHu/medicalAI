{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \u2b50 \u56fe\u50cf\u4eae\u70b9\u8bc6\u522b\u5206\u7c7b\u6a21\u578b\n", "\u672c\u9879\u76ee\u6839\u636e\u56fe\u50cf\u4e2d\u767d\u70b9\u7684\u4eae\u5ea6\u3001\u5f62\u72b6\u7279\u5f81\u5bf9\u56fe\u50cf\u8fdb\u884c\u4e8c\u5206\u7c7b\uff080 \u6216 1\uff09\u3002"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \ud83d\udce6 \u5bfc\u5165\u5e93\n", "import cv2\n", "import numpy as np\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import accuracy_score\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\uddf9 \u56fe\u50cf\u9884\u5904\u7406\u51fd\u6570"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def preprocess_image(img_path):\n", "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n", "    img = cv2.resize(img, (256, 256))\n", "    _, binary = cv2.threshold(img, 30, 255, cv2.THRESH_BINARY)\n", "    return binary, img"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcd0 \u7279\u5f81\u63d0\u53d6\u51fd\u6570"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def extract_features(binary_img, gray_img):\n", "    contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n", "    num_objects = len(contours)\n", "    avg_brightness = np.mean(gray_img[gray_img > 30]) if np.any(gray_img > 30) else 0\n", "    avg_area = np.mean([cv2.contourArea(c) for c in contours]) if contours else 0\n", "    avg_circularity = np.mean([\n", "        (4 * np.pi * cv2.contourArea(c)) / (cv2.arcLength(c, True)**2 + 1e-6)\n", "        for c in contours if cv2.arcLength(c, True) > 0\n", "    ]) if contours else 0\n", "    return [num_objects, avg_brightness, avg_area, avg_circularity]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83c\udfd7\ufe0f \u6784\u5efa\u8bad\u7ec3\u6570\u636e\u5e76\u8bad\u7ec3\u6a21\u578b"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u66ff\u6362\u4e3a\u4f60\u81ea\u5df1\u7684\u56fe\u50cf\u8def\u5f84\n", "image_paths = ['NCI6_XY10000.png', 'CAR T-Cell tracks_NCI2_T001_XY1.png']\n", "labels = [0, 1]\n", "\n", "X, y = [], []\n", "for path, label in zip(image_paths, labels):\n", "    binary, gray = preprocess_image(path)\n", "    features = extract_features(binary, gray)\n", "    X.append(features)\n", "    y.append(label)\n", "\n", "clf = RandomForestClassifier(n_estimators=50)\n", "clf.fit(X, y)\n", "print(\"\u6a21\u578b\u8bad\u7ec3\u5b8c\u6210 \u2705\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd0d \u63a8\u7406\u51fd\u6570"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def predict_image(path, model):\n", "    binary, gray = preprocess_image(path)\n", "    feat = extract_features(binary, gray)\n", "    return model.predict([feat])[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u9884\u6d4b\n", "print(\"\u56fe\u50cf1 \u9884\u6d4b\u7ed3\u679c:\", predict_image('NCI6_XY10000.png', clf))  # \u671f\u671b 0\n", "print(\"\u56fe\u50cf2 \u9884\u6d4b\u7ed3\u679c:\", predict_image('CAR T-Cell tracks_NCI2_T001_XY1.png', clf))  # \u671f\u671b 1"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}